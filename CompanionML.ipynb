{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CompanionML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMQIGOL0C-dQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "59d08e87-60a2-4314-db8d-3c545d223e09"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM,Dense,Dropout,Embedding,Bidirectional\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSKx7Mb9bxyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "f046a055-601a-4f19-fd4f-3ef5bf06df29"
      },
      "source": [
        "import gensim.downloader as api\n",
        "glove_wiki = api.load(\"glove-wiki-gigaword-50\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n68HvrlCcl7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def get_w2v_general(text, size, vectors, aggregation='mean'):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0.\n",
        "    for word in text.split():\n",
        "        try:\n",
        "            vec += vectors[word].reshape((1, size))\n",
        "            count += 1.\n",
        "        except KeyError:\n",
        "            continue\n",
        "    if aggregation == 'mean':\n",
        "        if count != 0:\n",
        "            vec /= count\n",
        "        return vec\n",
        "    elif aggregation == 'sum':\n",
        "        return vec"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdDqzx0VCnJv",
        "colab_type": "text"
      },
      "source": [
        "# **Companionship**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stjhvCy0K9uV",
        "colab_type": "text"
      },
      "source": [
        "# **GloVe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0Ceuy-uC17h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_df = pd.read_csv('social_liwc_final.csv')\n",
        "test_df = pd.read_csv('social_liwc_test.csv')\n",
        "\n",
        "x_train = my_df['clean_text']\n",
        "y_train = my_df['companionship']\n",
        "x_valid = test_df['clean_text']\n",
        "y_validation = test_df['companionship']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWMtR2PdclEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_vecs_glove_mean_wiki = scale(np.concatenate([get_w2v_general(z, 50, glove_wiki,'mean') for z in x_train.astype(str)]))\n",
        "validation_vecs_glove_mean_wiki = scale(np.concatenate([get_w2v_general(z, 50, glove_wiki,'mean') for z in x_valid.astype(str)]))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYgIkANyB_H2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "9e84586f-b410-4b14-8443-ea7bcfa85b2e"
      },
      "source": [
        "clf = LogisticRegression()\n",
        "clf.fit(train_vecs_glove_mean_wiki, y_train)\n",
        "score=clf.score(validation_vecs_glove_mean_wiki, y_validation)\n",
        "print('score',score)\n",
        "\n",
        "clf.score(validation_vecs_glove_mean_wiki, y_validation)\n",
        "ypredrf = clf.predict(validation_vecs_glove_mean_wiki)\n",
        "print('classification report')\n",
        "print(metrics.classification_report(y_validation, ypredrf))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score 0.9647058823529412\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98        80\n",
            "           1       1.00      0.40      0.57         5\n",
            "\n",
            "    accuracy                           0.96        85\n",
            "   macro avg       0.98      0.70      0.78        85\n",
            "weighted avg       0.97      0.96      0.96        85\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9igcsEW2JPx-",
        "colab_type": "text"
      },
      "source": [
        "# **LIWC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blo8WUQ1FyAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=my_df\n",
        "X_valid=test_df\n",
        "\n",
        "enc = StandardScaler()\n",
        "\n",
        "xtrain_onhot_social = enc.fit_transform(np.array(X_train['social']).reshape(-1,1))\n",
        "xvalid_onhot_social =enc.transform(np.array(X_valid['social']).reshape(-1,1))\n",
        "\n",
        "xtrain_onhot_time =enc.fit_transform(np.array(X_train['time']).reshape(-1,1))\n",
        "xvalid_onhot_time = enc.transform(np.array(X_valid['time']).reshape(-1,1))\n",
        "\n",
        "xtrain_onhot_we = enc.fit_transform(np.array(X_train['we']).reshape(-1,1))\n",
        "xvalid_onhot_we = enc.transform(np.array(X_valid['we']).reshape(-1,1))\n",
        "\n",
        "xtrain_onhot_pos = enc.fit_transform(np.array(X_train['pos']).reshape(-1,1))\n",
        "xvalid_onhot_pos = enc.transform(np.array(X_valid['pos']).reshape(-1,1))\n",
        "\n",
        "\n",
        "xtrain_onhot_neg = enc.fit_transform(np.array(X_train['neg']).reshape(-1,1))\n",
        "xvalid_onhot_neg = enc.transform(np.array(X_valid['neg']).reshape(-1,1))\n",
        "\n",
        "\n",
        "xtrain_onhot_cer = enc.fit_transform(np.array(X_train['cer']).reshape(-1,1))\n",
        "xvalid_onhot_cer = enc.transform(np.array(X_valid['cer']).reshape(-1,1))\n",
        "\n",
        "xtrain_onhot_intero = enc.fit_transform(np.array(X_train['intero']).reshape(-1,1))\n",
        "xvalid_onhot_intero = enc.transform(np.array(X_valid['intero']).reshape(-1,1))\n",
        "\n",
        "\n",
        "xtrain_onhot_health = enc.fit_transform(np.array(X_train['health']).reshape(-1,1))\n",
        "xvalid_onhot_health = enc.transform(np.array(X_valid['health']).reshape(-1,1))\n",
        "\n",
        "xtrain_onhot_family = enc.fit_transform(np.array(X_train['family']).reshape(-1,1))\n",
        "xvalid_onhot_family = enc.transform(np.array(X_valid['family']).reshape(-1,1))\n",
        "\n",
        "xtrain_onhot_achieve = enc.fit_transform(np.array(X_train['achieve']).reshape(-1,1))\n",
        "xvalid_onhot_achieve = enc.transform(np.array(X_valid['achieve']).reshape(-1,1))\n",
        "\n",
        "xtrain_onhot_work = enc.fit_transform(np.array(X_train['work']).reshape(-1,1))\n",
        "xvalid_onhot_work = enc.transform(np.array(X_valid['work']).reshape(-1,1))\n",
        "\n",
        "xtrain_onhot_leisure = enc.fit_transform(np.array(X_train['leisure']).reshape(-1,1))\n",
        "xvalid_onhot_leisure = enc.transform(np.array(X_valid['leisure']).reshape(-1,1))\n",
        "\n",
        "xtrain_onhot_they = enc.fit_transform(np.array(X_train['they']).reshape(-1,1))\n",
        "xvalid_onhot_they = enc.transform(np.array(X_valid['they']).reshape(-1,1))\n",
        "\n",
        "xtrain_onhot_relig =enc.fit_transform(np.array(X_train['relig']).reshape(-1,1))\n",
        "xvalid_onhot_relig = enc.transform(np.array(X_valid['relig']).reshape(-1,1))\n",
        "\n",
        "xtrain_onhot_assent = enc.fit_transform(np.array(X_train['assent']).reshape(-1,1))\n",
        "xvalid_onhot_assent = enc.transform(np.array(X_valid['assent']).reshape(-1,1))\n",
        "\n",
        "xtrain_onhot_money = enc.fit_transform(np.array(X_train['money']).reshape(-1,1))\n",
        "xvalid_onhot_money = enc.transform(np.array(X_valid['money']).reshape(-1,1))\n",
        "\n",
        "xtrain_onhot_ppron = enc.fit_transform(np.array(X_train['ppron']).reshape(-1,1))\n",
        "xvalid_onhot_ppron =enc.transform(np.array(X_valid['ppron']).reshape(-1,1))\n",
        "\n",
        "xtrain_onhot_affect = enc.fit_transform(np.array(X_train['affect']).reshape(-1,1))\n",
        "xvalid_onhot_affect = enc.transform(np.array(X_valid['affect']).reshape(-1,1))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWQV-h7-ROco",
        "colab_type": "text"
      },
      "source": [
        "**Only LIWC feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hppdxUFLkmp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "b3bf500c-502b-49a5-c8c5-ea9bd0d5e7d7"
      },
      "source": [
        "xtrain_tfidf = np.hstack([xtrain_onhot_social, xtrain_onhot_time, xtrain_onhot_we, xtrain_onhot_pos, xtrain_onhot_neg,xtrain_onhot_cer, xtrain_onhot_intero, xtrain_onhot_health, xtrain_onhot_family, xtrain_onhot_achieve, xtrain_onhot_work, xtrain_onhot_leisure, xtrain_onhot_they, xtrain_onhot_relig, xtrain_onhot_assent, xtrain_onhot_money, xtrain_onhot_ppron, xtrain_onhot_affect])\n",
        "xvalid_tfidf = np.hstack([xvalid_onhot_social, xvalid_onhot_time, xvalid_onhot_we, xvalid_onhot_pos, xvalid_onhot_neg,xvalid_onhot_cer, xvalid_onhot_intero, xvalid_onhot_health, xvalid_onhot_family, xvalid_onhot_achieve, xvalid_onhot_work, xvalid_onhot_leisure, xvalid_onhot_they, xvalid_onhot_relig, xvalid_onhot_assent, xvalid_onhot_money, xvalid_onhot_ppron, xvalid_onhot_affect])\n",
        "\n",
        "y_valid=y_validation\n",
        "clf = LogisticRegression()\n",
        "clf.fit(xtrain_tfidf,y_train)\n",
        "print(\"Testing accuracy: {}\".format(clf.score(xvalid_tfidf, y_valid)))\n",
        "prediction_all = clf.predict(xvalid_tfidf)\n",
        "print(\"Classification report\",classification_report(y_valid, prediction_all))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9411764705882353\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97        80\n",
            "           1       0.50      0.20      0.29         5\n",
            "\n",
            "    accuracy                           0.94        85\n",
            "   macro avg       0.73      0.59      0.63        85\n",
            "weighted avg       0.93      0.94      0.93        85\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rcxEeR4RTJV",
        "colab_type": "text"
      },
      "source": [
        "**GloVe + LIWC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_TDVPBaRR3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "b5c4b699-1b5b-4f49-f584-7b4fc94ad617"
      },
      "source": [
        "#with glove and all LIWC feature\n",
        "xtrain_tfidf = np.hstack([xtrain_onhot_social, xtrain_onhot_time, xtrain_onhot_we, xtrain_onhot_pos, xtrain_onhot_neg,xtrain_onhot_cer, xtrain_onhot_intero, xtrain_onhot_health, xtrain_onhot_family, xtrain_onhot_achieve, xtrain_onhot_work, xtrain_onhot_leisure, xtrain_onhot_they, xtrain_onhot_relig, xtrain_onhot_assent, xtrain_onhot_money, xtrain_onhot_ppron, xtrain_onhot_affect,train_vecs_glove_mean_wiki])\n",
        "xvalid_tfidf = np.hstack([xvalid_onhot_social, xvalid_onhot_time, xvalid_onhot_we, xvalid_onhot_pos, xvalid_onhot_neg,xvalid_onhot_cer, xvalid_onhot_intero, xvalid_onhot_health, xvalid_onhot_family, xvalid_onhot_achieve, xvalid_onhot_work, xvalid_onhot_leisure, xvalid_onhot_they, xvalid_onhot_relig, xvalid_onhot_assent, xvalid_onhot_money, xvalid_onhot_ppron, xvalid_onhot_affect,validation_vecs_glove_mean_wiki])\n",
        "\n",
        "y_valid=y_validation\n",
        "clf = LogisticRegression()\n",
        "clf.fit(xtrain_tfidf,y_train)\n",
        "print(\"Testing accuracy: {}\".format(clf.score(xvalid_tfidf, y_valid)))\n",
        "\n",
        "prediction_all = clf.predict(xvalid_tfidf)\n",
        "print(classification_report(y_valid, prediction_all))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9647058823529412\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98        80\n",
            "           1       1.00      0.40      0.57         5\n",
            "\n",
            "    accuracy                           0.96        85\n",
            "   macro avg       0.98      0.70      0.78        85\n",
            "weighted avg       0.97      0.96      0.96        85\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHZvXmcILUOV",
        "colab_type": "text"
      },
      "source": [
        "# **Stanford coreNLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtBwsjMBLZDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=my_df\n",
        "X_valid=test_df\n",
        "enc = StandardScaler()\n",
        "xtrain_onhot_senti = enc.fit_transform(np.array(X_train['sentiment']).reshape(-1,1))\n",
        "xvalid_onhot_senti =enc.transform(np.array(X_valid['sentiment']).reshape(-1,1))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytXgSOYJSNBO",
        "colab_type": "text"
      },
      "source": [
        "**Only Stanford coreNLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj4XiCzOMAIu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "c473446c-e504-449d-bc02-76bc9844e186"
      },
      "source": [
        "y_valid=y_validation\n",
        "clf = LogisticRegression()\n",
        "clf.fit(xtrain_onhot_senti,y_train)\n",
        "print(\"Testing accuracy: {}\".format(clf.score(xvalid_onhot_senti, y_valid)))\n",
        "prediction_all = clf.predict(xvalid_onhot_senti)\n",
        "print(\"Classification report\",classification_report(y_valid, prediction_all))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9411764705882353\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97        80\n",
            "           1       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.94        85\n",
            "   macro avg       0.47      0.50      0.48        85\n",
            "weighted avg       0.89      0.94      0.91        85\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFsxQ79zSSj7",
        "colab_type": "text"
      },
      "source": [
        "**GloVe + LIWC + Stanford coreNLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHVLPAkTSQl_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "fd769870-26df-4b98-f351-0759c1f3cb53"
      },
      "source": [
        "#with glove +LIWC +Stanford coreNLP feature\n",
        "xtrain_tfidf = np.hstack([xtrain_onhot_social, xtrain_onhot_time, xtrain_onhot_we, xtrain_onhot_pos, xtrain_onhot_neg,xtrain_onhot_cer, xtrain_onhot_intero, xtrain_onhot_health, xtrain_onhot_family, xtrain_onhot_achieve, xtrain_onhot_work, xtrain_onhot_leisure, xtrain_onhot_they, xtrain_onhot_relig, xtrain_onhot_assent, xtrain_onhot_money, xtrain_onhot_ppron, xtrain_onhot_affect,train_vecs_glove_mean_wiki,xtrain_onhot_senti])\n",
        "xvalid_tfidf = np.hstack([xvalid_onhot_social, xvalid_onhot_time, xvalid_onhot_we, xvalid_onhot_pos, xvalid_onhot_neg,xvalid_onhot_cer, xvalid_onhot_intero, xvalid_onhot_health, xvalid_onhot_family, xvalid_onhot_achieve, xvalid_onhot_work, xvalid_onhot_leisure, xvalid_onhot_they, xvalid_onhot_relig, xvalid_onhot_assent, xvalid_onhot_money, xvalid_onhot_ppron, xvalid_onhot_affect,validation_vecs_glove_mean_wiki,xvalid_onhot_senti])\n",
        "\n",
        "y_valid=y_validation\n",
        "clf = LogisticRegression()\n",
        "clf.fit(xtrain_tfidf,y_train)\n",
        "print(\"Testing accuracy: {}\".format(clf.score(xvalid_tfidf, y_valid)))\n",
        "\n",
        "prediction_all = clf.predict(xvalid_tfidf)\n",
        "print(classification_report(y_valid, prediction_all))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9647058823529412\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98        80\n",
            "           1       1.00      0.40      0.57         5\n",
            "\n",
            "    accuracy                           0.96        85\n",
            "   macro avg       0.98      0.70      0.78        85\n",
            "weighted avg       0.97      0.96      0.96        85\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9MUNuCsJV2M",
        "colab_type": "text"
      },
      "source": [
        "# **TF-IDF N-gram**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mCOMVqOFzSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_transformer = TfidfVectorizer(use_idf=True,ngram_range=(1,3)) \n",
        "tfidf_train_data = tfidf_transformer.fit_transform(X_train['clean_text'])\n",
        "tfidf_test_data = tfidf_transformer.transform(X_valid['clean_text'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-1Ac3UwSt63",
        "colab_type": "text"
      },
      "source": [
        "**Only Ngram**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKJTo_2_MNFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "35452977-15f4-4834-e1ad-7e57582ca98f"
      },
      "source": [
        "y_valid=y_validation\n",
        "clf = LogisticRegression()\n",
        "clf.fit(tfidf_train_data.toarray(),y_train)\n",
        "print(\"Testing accuracy: {}\".format(clf.score(tfidf_test_data.toarray(), y_valid)))\n",
        "prediction_all = clf.predict(tfidf_test_data.toarray())\n",
        "print(classification_report(y_valid, prediction_all))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9411764705882353\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97        80\n",
            "           1       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.94        85\n",
            "   macro avg       0.47      0.50      0.48        85\n",
            "weighted avg       0.89      0.94      0.91        85\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRvFPSbwSxEx",
        "colab_type": "text"
      },
      "source": [
        "**GloVe + LIWC + Sentiment + Ngram**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_rgjMADJch0",
        "colab_type": "text"
      },
      "source": [
        "# **All Features (gloVe + LIWC + Sentiment + Ngram)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX1hpJoeGZXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#with glove and all feature\n",
        "xtrain_tfidf = np.hstack([xtrain_onhot_social, xtrain_onhot_time, xtrain_onhot_we, xtrain_onhot_pos, xtrain_onhot_neg,xtrain_onhot_cer, xtrain_onhot_intero, xtrain_onhot_health, xtrain_onhot_family, xtrain_onhot_achieve, xtrain_onhot_work, xtrain_onhot_leisure, xtrain_onhot_they, xtrain_onhot_relig, xtrain_onhot_assent, xtrain_onhot_money, xtrain_onhot_ppron, xtrain_onhot_affect,xtrain_onhot_senti,tfidf_train_data.toarray(),train_vecs_glove_mean_wiki])\n",
        "xvalid_tfidf = np.hstack([xvalid_onhot_social, xvalid_onhot_time, xvalid_onhot_we, xvalid_onhot_pos, xvalid_onhot_neg,xvalid_onhot_cer, xvalid_onhot_intero, xvalid_onhot_health, xvalid_onhot_family, xvalid_onhot_achieve, xvalid_onhot_work, xvalid_onhot_leisure, xvalid_onhot_they, xvalid_onhot_relig, xvalid_onhot_assent, xvalid_onhot_money, xvalid_onhot_ppron, xvalid_onhot_affect,xvalid_onhot_senti,tfidf_test_data.toarray(),validation_vecs_glove_mean_wiki])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-4LxFozHEbz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "bb479b43-38ee-42b5-87e2-3aedb0eeb9db"
      },
      "source": [
        "y_valid=y_validation\n",
        "clf = LogisticRegression()\n",
        "clf.fit(xtrain_tfidf,y_train)\n",
        "print(\"Testing accuracy: {}\".format(clf.score(xvalid_tfidf, y_valid)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9647058823529412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNSw9zTFHcLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "13361472-2ea4-41ad-a325-b5a7661aa792"
      },
      "source": [
        "prediction_all = clf.predict(xvalid_tfidf)\n",
        "print(classification_report(y_valid, prediction_all))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98        80\n",
            "           1       1.00      0.40      0.57         5\n",
            "\n",
            "    accuracy                           0.96        85\n",
            "   macro avg       0.98      0.70      0.78        85\n",
            "weighted avg       0.97      0.96      0.96        85\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}